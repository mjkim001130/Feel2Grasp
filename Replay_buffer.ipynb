{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joy4mj/miniconda3/envs/so101/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 53936\n",
      "len(ds) = 53936\n",
      "ds.meta = LeRobotDatasetMetadata({\n",
      "    Repository ID: 'mjkim00/Feel2Grasp',\n",
      "    Total episodes: '200',\n",
      "    Total frames: '53936',\n",
      "    Features: '['action', 'observation.state', 'observation.images.front', 'observation.images.left', 'observation.images.right', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index']',\n",
      "})',\n",
      "\n",
      "encoded 256/53936\n",
      "encoded 5376/53936\n",
      "encoded 10496/53936\n",
      "encoded 15616/53936\n",
      "encoded 20736/53936\n",
      "encoded 25856/53936\n",
      "encoded 30976/53936\n",
      "encoded 36096/53936\n",
      "encoded 41216/53936\n",
      "encoded 46336/53936\n",
      "encoded 51456/53936\n",
      "Saved: replay_buffer_iql_72d.npz\n",
      "Shapes: S (53936, 72) A (53936, 6) R (53936,) S' (53936, 72) D (53936,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "\n",
    "# ======================== Configuration ========================\n",
    "parquet_path = \"/home/joy4mj/Feel2Grasp/train.parquet\" \n",
    "repo_id = \"mjkim00/Feel2Grasp\"\n",
    "revision = \"main\"\n",
    "video_backend = \"pyav\"\n",
    "\n",
    "encoder_ckpt_path = \"./ae_out/encoder.pt\"\n",
    "batch_size = 256\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "out_path = \"replay_buffer_iql_72d.npz\"\n",
    "\n",
    "\n",
    "# Encoder\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),\n",
    "        )\n",
    "        self.fc = nn.Linear(256 * 4 * 4, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.net(x).flatten(1))\n",
    "\n",
    "ckpt = torch.load(encoder_ckpt_path, map_location=\"cpu\")\n",
    "encoder = ConvEncoder(ckpt[\"latent_dim\"])\n",
    "encoder.load_state_dict(ckpt[\"encoder_state_dict\"])\n",
    "encoder.to(device).eval()\n",
    "for p in encoder.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "resize_hw = tuple(ckpt[\"resize_hw\"])  # (H, W)\n",
    "\n",
    "# Parquet load\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "need_cols = [\n",
    "    \"action\", \"observation.state\", \"episode_index\", \"frame_index\", \"index\",\n",
    "    \"left_image_circle\", \"right_image_circle\", \"circle_reward\"\n",
    "]\n",
    "missing = [c for c in need_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing columns: {missing}\\nAvailable: {list(df.columns)}\")\n",
    "\n",
    "df = df.sort_values([\"episode_index\", \"frame_index\"]).reset_index(drop=True)\n",
    "\n",
    "N = len(df)\n",
    "print(\"N =\", N)\n",
    "\n",
    "ep = df[\"episode_index\"].to_numpy()\n",
    "fr = df[\"frame_index\"].to_numpy()\n",
    "global_idx = df[\"index\"].to_numpy()\n",
    "\n",
    "dup = df.duplicated([\"episode_index\", \"frame_index\"]).any()\n",
    "if dup:\n",
    "    raise ValueError(\"Duplicated (episode_index, frame_index) rows exist in parquet. Fix this first.\")\n",
    "\n",
    "# observation.state / action stack\n",
    "obs_state = np.stack(df[\"observation.state\"].to_list()).astype(np.float32)  # (N,6) \n",
    "actions   = np.stack(df[\"action\"].to_list()).astype(np.float32)            # (N,Da)\n",
    "lr01      = df[[\"left_image_circle\", \"right_image_circle\"]].to_numpy().astype(np.float32)  # (N,2)\n",
    "rewards   = df[\"circle_reward\"].to_numpy().astype(np.float32)              # (N,)\n",
    "\n",
    "if obs_state.ndim != 2 or obs_state.shape[1] != 6:\n",
    "    raise ValueError(f\"observation.state expected (N,6) but got {obs_state.shape}\")\n",
    "\n",
    "# reward rescaling\n",
    "rewards = rewards / 10.0\n",
    "\n",
    "\n",
    "# load LeRobotDataset 로드\n",
    "ds = LeRobotDataset(repo_id, revision=revision, video_backend=video_backend)\n",
    "print(\"len(ds) =\", len(ds))\n",
    "print(\"ds.meta =\", ds.meta)\n",
    "\n",
    "def get_sample(ds, i: int):\n",
    "    s = ds[int(i)]\n",
    "    return s\n",
    "\n",
    "def get_key(sample, key):\n",
    "    if key in sample:\n",
    "        return sample[key]\n",
    "    raise KeyError(f\"Key {key} not found in sample keys: {list(sample.keys())[:30]} ...\")\n",
    "\n",
    "check_k = min(200, N)\n",
    "ok_direct = True\n",
    "for k in np.linspace(0, N-1, check_k, dtype=int):\n",
    "    i = int(global_idx[k])\n",
    "    samp = get_sample(ds, i)\n",
    "    ep_ds = int(get_key(samp, \"episode_index\"))\n",
    "    fr_ds = int(get_key(samp, \"frame_index\"))\n",
    "    if ep_ds != int(ep[k]) or fr_ds != int(fr[k]):\n",
    "        ok_direct = False\n",
    "        break\n",
    "\n",
    "if not ok_direct:\n",
    "    print(\"[WARN] parquet.index != ds index mapping. Building (episode,frame)->ds_index map...\")\n",
    "    map_epfr_to_dsidx = {}\n",
    "    for i in range(len(ds)):\n",
    "        samp = get_sample(ds, i)\n",
    "        ep_i = int(get_key(samp, \"episode_index\"))\n",
    "        fr_i = int(get_key(samp, \"frame_index\"))\n",
    "        map_epfr_to_dsidx[(ep_i, fr_i)] = i\n",
    "\n",
    "    ds_indices = np.empty((N,), dtype=np.int64)\n",
    "    for k in range(N):\n",
    "        key = (int(ep[k]), int(fr[k]))\n",
    "        if key not in map_epfr_to_dsidx:\n",
    "            raise KeyError(f\"Cannot find ds index for (episode,frame)={key}\")\n",
    "        ds_indices[k] = map_epfr_to_dsidx[key]\n",
    "else:\n",
    "    ds_indices = global_idx.astype(np.int64)\n",
    "\n",
    "# front image -> encoder -> z(64) \n",
    "@torch.no_grad()\n",
    "def encode_front_batch(ds, idx_batch):\n",
    "    imgs = []\n",
    "    for i in idx_batch:\n",
    "        samp = get_sample(ds, int(i))\n",
    "        img = get_key(samp, \"observation.images.front\")  # torch.Tensor or np.ndarray\n",
    "        # (3,H,W) float32 [0,1]\n",
    "        if isinstance(img, np.ndarray):\n",
    "            if img.ndim == 3 and img.shape[-1] == 3:  # HWC\n",
    "                img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "            else:\n",
    "                img = torch.from_numpy(img)\n",
    "        # torch tensor\n",
    "        if img.dtype == torch.uint8:\n",
    "            img = img.float() / 255.0\n",
    "        else:\n",
    "            img = img.float()\n",
    "            # 값 범위가 0~255면 나누기\n",
    "            if img.max() > 1.5:\n",
    "                img = img / 255.0\n",
    "\n",
    "        imgs.append(img)\n",
    "\n",
    "    x = torch.stack(imgs, dim=0).to(device)  # (B,3,H,W)\n",
    "    x = F.interpolate(x, size=resize_hw, mode=\"bilinear\", align_corners=False)\n",
    "    z = encoder(x)  # (B,64)\n",
    "    return z.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "Z = np.empty((N, ckpt[\"latent_dim\"]), dtype=np.float32)\n",
    "\n",
    "for start in range(0, N, batch_size):\n",
    "    end = min(N, start + batch_size)\n",
    "    Z[start:end] = encode_front_batch(ds, ds_indices[start:end])\n",
    "    if (start // batch_size) % 20 == 0:\n",
    "        print(f\"encoded {end}/{N}\")\n",
    "\n",
    "# state = [z64, left01, right01, obs_state6]\n",
    "states = np.concatenate([Z, lr01, obs_state], axis=1).astype(np.float32)  # (N,72)\n",
    "if states.shape[1] != 72:\n",
    "    raise ValueError(f\"states dim expected 72 but got {states.shape}\")\n",
    "\n",
    "\n",
    "# done / next_state \n",
    "terminals = np.zeros((N,), dtype=np.float32)\n",
    "# t가 terminal이면: 다음 row가 (same ep & frame+1)가 아님\n",
    "cont = (ep[1:] == ep[:-1]) & (fr[1:] == fr[:-1] + 1)\n",
    "terminals[:-1] = (~cont).astype(np.float32)\n",
    "terminals[-1] = 1.0\n",
    "\n",
    "next_states = np.empty_like(states)\n",
    "next_states[:-1] = states[1:]\n",
    "next_states[-1] = states[-1]\n",
    "\n",
    "terminal_idx = np.where(terminals > 0.5)[0]\n",
    "next_states[terminal_idx] = states[terminal_idx]\n",
    "\n",
    "\n",
    "np.savez_compressed(\n",
    "    out_path,\n",
    "    observations=states,\n",
    "    actions=actions.astype(np.float32),\n",
    "    rewards=rewards.astype(np.float32),\n",
    "    next_observations=next_states,\n",
    "    terminals=terminals,\n",
    "    episode_index=ep.astype(np.int32),\n",
    "    frame_index=fr.astype(np.int32),\n",
    "    ds_index=ds_indices.astype(np.int64),\n",
    ")\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"Shapes:\",\n",
    "      \"S\", states.shape,\n",
    "      \"A\", actions.shape,\n",
    "      \"R\", rewards.shape,\n",
    "      \"S'\", next_states.shape,\n",
    "      \"D\", terminals.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: episode/timestep alignment is consistent.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "d = np.load(\"replay_buffer_iql_72d.npz\")\n",
    "ep = d[\"episode_index\"]\n",
    "fr = d[\"frame_index\"]\n",
    "done = d[\"terminals\"]\n",
    "\n",
    "# check episode/timestep alignment\n",
    "idx = np.where(done[:-1] < 0.5)[0]\n",
    "assert np.all(ep[idx] == ep[idx+1]), \"Found done=0 but episode changes!\"\n",
    "assert np.all(fr[idx+1] == fr[idx] + 1), \"Found done=0 but frame_index not consecutive!\"\n",
    "\n",
    "# done==1 \n",
    "idx = np.where(done[:-1] > 0.5)[0]\n",
    "bad = np.where((ep[idx] == ep[idx+1]) & (fr[idx+1] == fr[idx] + 1))[0]\n",
    "assert len(bad) == 0, \"Found done=1 but next is still a valid continuation!\"\n",
    "\n",
    "print(\"OK: episode/timestep alignment is consistent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 53936\n",
      "reward min/max: -0.1 1.0\n",
      "count success: 5932\n",
      "success ratio: 0.10998220112726194\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = np.load(\"replay_buffer_iql_normalized.npz\")\n",
    "r = d[\"rewards\"]\n",
    "print(\"N:\", len(r))\n",
    "print(\"reward min/max:\", r.min(), r.max())\n",
    "print(\"count success:\", (r > 0.9).sum())   \n",
    "print(\"success ratio:\", (r > 0.9).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d960403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "so101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
